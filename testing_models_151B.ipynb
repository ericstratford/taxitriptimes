{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7924250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788f46df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2a47d",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba36ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# Custom Dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.float()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index].float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86060645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, optimizer, loss_function):\n",
    "    losses = []\n",
    "    # get a batch of training data from the train_loader (DataLoader obj)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        x = data[:,:-1].to(device)\n",
    "        t = data[:,-1].to(device)\n",
    "        # make predictions for this batch\n",
    "        y = model(x)\n",
    "        # Compute the loss\n",
    "        loss = loss_function(y, t)\n",
    "        # zero out the gradients so that it will not accumulate through each iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the gradents with the backward call (backprop)\n",
    "        loss.backward()\n",
    "        # Update weight using gradient descent \n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)\n",
    "\n",
    "def eval_epoch(valid_loader, model, loss_function):\n",
    "    rmses = []\n",
    "    with torch.no_grad(): \n",
    "        for i, data in enumerate(valid_loader):\n",
    "            x = data[:,:-1].to(device)\n",
    "            t = data[:,-1].to(device)\n",
    "            # Compute prediction\n",
    "            y = model(x).squeeze()\n",
    "            \n",
    "            rmse = math.sqrt(loss_function(y,t))\n",
    "            rmses.append(rmse)\n",
    "            \n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6013035",
   "metadata": {},
   "source": [
    "# Define Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5fa0599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.fc1 = nn.Linear(69, 64)\n",
    "#         self.fc2 = nn.Linear(64, 48)\n",
    "#         self.fc3 = nn.Linear(48, 32)\n",
    "#         self.fc4 = nn.Linear(32,32)\n",
    "#         self.fc5 = nn.Linear(32, 16)  \n",
    "#         self.fc6 = nn.Linear(16, 1)   \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = leaky_relu(self.fc1(x))\n",
    "#         x = leaky_relu(self.fc2(x))\n",
    "#         x = leaky_relu(self.fc3(x))     \n",
    "#         x = leaky_relu(self.fc4(x))   \n",
    "#         x = leaky_relu(self.fc5(x))\n",
    "#         x = self.fc6(x)\n",
    "#         return x\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(69, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 8)\n",
    "        self.fc4 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))     \n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the neural network\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd437171",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "221b2f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1710670, 70)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_np = np.load('processed_train_set.npy')\n",
    "df_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d723ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in np array and DRAW SAMPLE\n",
    "num_samples = int(df_np.shape[0]*0.1)\n",
    "\n",
    "num_rows = df_np.shape[0]\n",
    "sampled_indices = np.random.choice(num_rows, size=num_samples, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39e0d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert np to tensor\n",
    "df = torch.tensor(df_np[sampled_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4cf35d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([171067, 70])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00fe0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset\n",
    "dataset = MyDataset(df)\n",
    "\n",
    "# Define the sizes of train, validation, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset)-train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29def452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "batch_size = 32\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader objects for train, validation, and test sets\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "# test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ccf15",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80db77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model = model, model_name = 'main_model', epochs = 10, lr=0.00001, batch_size = batch_size):\n",
    "    # Define the optimizer\n",
    "    train_rmses = []\n",
    "    valid_rmses = []\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    epochs = 10\n",
    "    train_accs, valid_accs = [], []\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train() # gradient tracking is on\n",
    "\n",
    "        train_loss = train_epoch(train_loader, model, optimizer, criterion)\n",
    "\n",
    "        model.eval() # we don't need gradients on to do reporting\n",
    "\n",
    "        train_rmse = eval_epoch(train_loader, model, criterion)\n",
    "        valid_rmse = eval_epoch(valid_loader, model, criterion)\n",
    "        \n",
    "#         train_rmses.append(train_rmse)\n",
    "#         valid_rmses.append(valid_rmse)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}, Train Loss: {train_loss:>0.4f}, Train mse: {train_rmse:>0.2f},\\\n",
    "              Validation Accuracy: {valid_rmse:>0.2f} \\n\")\n",
    "    torch.save(model.state_dict(), './{}'.format(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4baf9c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsiyed/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 459573.1677, Train mse: 549.61,              Validation Accuracy: 553.52 \n",
      "\n",
      "Epoch: 2, Train Loss: 459554.9581, Train mse: 552.13,              Validation Accuracy: 556.37 \n",
      "\n",
      "Epoch: 3, Train Loss: 459568.2017, Train mse: 551.99,              Validation Accuracy: 555.02 \n",
      "\n",
      "Epoch: 4, Train Loss: 459499.7235, Train mse: 550.66,              Validation Accuracy: 553.28 \n",
      "\n",
      "Epoch: 5, Train Loss: 459523.0944, Train mse: 550.01,              Validation Accuracy: 553.76 \n",
      "\n",
      "Epoch: 6, Train Loss: 459659.3452, Train mse: 552.47,              Validation Accuracy: 556.07 \n",
      "\n",
      "Epoch: 7, Train Loss: 459575.8223, Train mse: 548.58,              Validation Accuracy: 552.20 \n",
      "\n",
      "Epoch: 8, Train Loss: 459549.2536, Train mse: 548.27,              Validation Accuracy: 552.07 \n",
      "\n",
      "Epoch: 9, Train Loss: 459562.1353, Train mse: 550.50,              Validation Accuracy: 554.60 \n",
      "\n",
      "Epoch: 10, Train Loss: 459455.4579, Train mse: 549.81,              Validation Accuracy: 552.36 \n",
      "\n",
      "CPU times: user 2min 10s, sys: 2.69 s, total: 2min 13s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(model = model, model_name = 'main_model', \\\n",
    "epochs = 10, lr=0.00001, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a89d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a1085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41971fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model = Net()\n",
    "# saved_model.load_state_dict(torch.load('./cse151B_project'))\n",
    "# saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f4d3f",
   "metadata": {},
   "source": [
    "# Test Model (unfinished cuz eric poopoo code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_public.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf81988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encode time\n",
    "# Convert Unix timestamp to datetime\n",
    "test['datetime'] = pd.to_datetime(test['TIMESTAMP'], unit='s')\n",
    "\n",
    "# Extract year, month, day of the week, and hour of the day\n",
    "test['year'] = test['datetime'].dt.year\n",
    "test['month'] = test['datetime'].dt.month\n",
    "test['day_of_week'] = test['datetime'].dt.dayofweek\n",
    "test['hour_of_day'] = test['datetime'].dt.hour\n",
    "test_datetime = test\n",
    "\n",
    "# Create an instance of the OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "# categorical_cols = ['CALL_TYPE', 'year', 'month', 'day_of_week', 'hour_of_day']\n",
    "categorical_cols = ['CALL_TYPE']\n",
    "\n",
    "test_df_hot = test_datetime[categorical_cols].values\n",
    "\n",
    "# Fit the encoder on the categorical variable\n",
    "encoder.fit(test_df_hot)\n",
    "\n",
    "# Transform the categorical variable into one-hot encoded features\n",
    "test_hot_encoded = encoder.transform(test_df_hot).toarray()\n",
    "test_hot_encoded = pd.DataFrame(test_hot_encoded)\n",
    "# print(test_hot_encoded.shape)\n",
    "\n",
    "test_df_OHE = pd.concat([test_datetime,test_hot_encoded], axis = 1).drop(['TIMESTAMP','TRIP_ID','CALL_TYPE', 'DAY_TYPE', 'datetime'], axis = 1) # basic\n",
    "test_df_OHE = test_df_OHE.fillna(0)\n",
    "# test_hot = pd.DataFrame(test_hot_encoded, columns = encoder.get_feature_names_out(['CALL_TYPE', 'year', 'month', 'day_of_week', 'hour_of_day']))\n",
    "\n",
    "#basic\n",
    "test_df_basic = test_df_OHE.copy()\n",
    "test_df_basic['MISSING_DATA'] = test_df_basic['MISSING_DATA'].astype('int')\n",
    "test_df_basic.shape\n",
    "#basic\n",
    "\n",
    "# test_hot = test_hot.reindex(columns=df_hot.columns, fill_value=0)\n",
    "# test_hot\n",
    "cols = ['ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID', 'MISSING_DATA', 'year', 'month', 'day_of_week', 'hour_of_day', 'CALL_TYPE_A', 'CALL_TYPE_B', 'CALL_TYPE_C']\n",
    "test_df_basic = test_df_basic.reindex(columns=cols, fill_value=0)\n",
    "test_df_basic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc1d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76488140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cfcfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da518e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e12a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.tensor(test_df_basic.values).float().to(device)\n",
    "test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "for i in range(test_tensor.shape[0]):\n",
    "    test_pred.append(model_basic(test_tensor[i]).item())\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5487a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {'TRIP_ID': test['TRIP_ID'],\n",
    "    'TRAVEL_TIME': xg_pred}\n",
    "output = pd.DataFrame(data = test_data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('zeds_may25_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917014e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
